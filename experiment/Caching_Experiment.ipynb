{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Introduction</h1>\n",
    "<p>In this experiment, we will be running tests on various caching strategies. Their functionalities are described below.</p>\n",
    "<h3>Memory/No Cache</h3>\n",
    "<p>In this strategy, no cache is implemented, every memory lookup requires a memory access/hit. In this experiment, this would prove to be the baseline of comparison for other caching strategies.</p>\n",
    "<h3>Cyclic Cache</h3>\n",
    "<p>In this strategy, the cache is implemented as a queue-like structure since it follows the First-In-First-Out rule, also known as FIFO. In this caching method, if the element that we are looking for is found in the cache, we return it. If it is not, we dequeue the element at the start of the queue, access memory to fetch the element and add the element to the end of the queue.</p>\n",
    "<h3>Least Recently Used Cache</h3>\n",
    "<p>This caching method is also known as LRU in short. In this strategy, we could either use a 2D list or a combination of a dictionary and a list. The essence of its implementation is that if an element exists in the cache, we return it and change the ordering of the cache so that the element we just accessed is moved to the end of the list to signify that it is the most recently used address. If it is not found in the cache, we access memory to fetch it. After doing so, if the cache is full, we remove the first element of the list, which according to our implementation would be the least recently used address since the most recently used is located at the end of the list. After this, we add the address at the end of the list, again to signify that this was the most recently used element.</p>\n",
    "<h3>Random Cache</h3>\n",
    "<p>As the name suggests, this caching method evicts elements from the cache at random when the cache is full. It would be interesting to see how effective this strategy will prove to be as compared to the other ones.</p>\n",
    "\n",
    "<p>Through our experiments, we will try to answer the following questions about the various caching strategies:</p>\n",
    "<ul>\n",
    "    <li>How often does a lookup result in memory access?</li>\n",
    "    <li>Are there differences between the behaviour of the strategies></li>\n",
    "</ul>\n",
    "\n",
    "<p>I intend on answering these questions by testing how well the strategies perform under test cases of various sizes and spreads.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Experiment</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Let's start by first importing the caching strategies.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from memory import Memory, CyclicCache, LRUCache, RandomCache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Test Cases</h3>\n",
    "<p>We need to start by writing a function that can generate a random test case that each of the caching strategies can be tested against. The function should take as input the range of the data and its size. The closer together the data, the more the repetitions, and the more cache accesses we should have. We can then experiment the strategies under various test cases of different sizes and spreads.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 2, 3, 8, 8, 4, 4, 5, 5, 0]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "def generate_test_case(start, end, size):\n",
    "    test_case = [random.randint(start, end) for _ in range(size)]\n",
    "    return test_case\n",
    "generate_test_case(0, 10, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Evaluation</h3>\n",
    "<p>We need a function that can evaluate a provided test case against each of the caching strategies that we are comparing and return to us the get_hit_count value for each of them.</p>\n",
    "<p>Additionally, I have also taken the decision to suppress the print statements in the Memory file from here since they are being a bit distracting.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "def evaluate(test_case):\n",
    "    #sys.stdout = open(os.devnull, 'w')\n",
    "    # run the provided test_case against each of the strategies\n",
    "    scores = {}\n",
    "    strategies = [Memory(), LRUCache(), CyclicCache(), RandomCache()]\n",
    "    #mem = Memory()\n",
    "    for strategy in strategies:\n",
    "        for datum in test_case:\n",
    "            strategy.lookup(datum)\n",
    "        scores[strategy.name()] = strategy.get_hit_count()\n",
    "    sys.stdout = sys.__stdout__\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Testing</h3>\n",
    "<p>Now we need to start generating test cases using the function we made. The tests need to be of various sizes and cover different spreads. For each of the following tests, we will generate 100 random test cases since I think that a large sample size would give us a better idea.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repetitions = 100\n",
    "generate_test_cases = lambda start, end, size: [generate_test_case(start, end, size)\n",
    "                                               for _ in range(repetitions)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Small size over a small range</h4>\n",
    "<p>We will start by testing the strategies against test cases of a small size over a small range/spread. In this case, we would expect the produced test cases to be evenly spread out since we are assigning the size to be the same as the number of elements in the range.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_s_test_cases = generate_test_cases(0, 9, 10)\n",
    "# overall_scores denotes the sum of the scores for each strategy\n",
    "s_s_overall_scores = {'Cyclic': 0,\n",
    "                  'LRU':0,\n",
    "                  'Memory': 0,\n",
    "                  'Random': 0}\n",
    "for test_case in s_s_test_cases:\n",
    "    scores = evaluate(test_case)\n",
    "    for key in scores.keys():\n",
    "        s_s_overall_scores[key] += scores[key]\n",
    "\n",
    "sys.stdout = sys.__stdout__\n",
    "print(s_s_overall_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
